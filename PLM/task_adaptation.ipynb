{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74d3a7be-aa88-4ccc-910c-77a7149c7a74",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer, DataCollatorForLanguageModeling, Trainer, \\\n",
    "    TrainingArguments\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import DatasetDict, Dataset\n",
    "from pathlib import Path\n",
    "from pynvml import *\n",
    "import torch\n",
    "import argparse\n",
    "import sys\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import evaluate\n",
    "import math\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used // 1024 ** 2} MB.\")\n",
    "\n",
    "\n",
    "def print_summary(result):\n",
    "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
    "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
    "    print_gpu_utilization()\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, max_length=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12680bc5-c780-4ed7-8b49-57afa164bfe1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa20066e3f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parser = argparse.ArgumentParser(description='Task-adaptive model')\n",
    "# parser.add_argument('--model', help='Path to BERT-like model')\n",
    "# parser.add_argument('--model_name',\n",
    "#                     help='Name of the BERT-like model. Default = \"\" which corresponds to ClinicalBERT',\n",
    "#                     default='')\n",
    "# config = parser.parse_args(sys.argv[1:])\n",
    "task = 'sentiment' \n",
    "MODEL = 'UFNLP/gatortron-base'\n",
    "\n",
    "# set seed\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f7858d2-6fef-4fd4-ba11-f85b238fb6dc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d902026f073b4e6ca8bb89f6965b1375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/534 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fatal Python error: config_get_locale_encoding: failed to get the locale encoding: nl_langinfo(CODESET) failed\n",
      "Python runtime state: preinitialized\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc47b7e59b643f1958b1d32509ce8dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/379k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/346 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/87 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create task Dataset\n",
    "task_dt_path = 'task_adapt_sentences.csv'\n",
    "sentences = pd.read_csv(task_dt_path, header=None)\n",
    "sentences = sentences[0].str.lower().str.split('.').values.tolist()\n",
    "sentences = list(itertools.chain.from_iterable(sentences))\n",
    "\n",
    "train, dev = train_test_split(sentences, test_size=0.2, random_state=42)\n",
    "\n",
    "task_dt = {'train': {},\n",
    "           'dev': {}}\n",
    "           #'test': {}}\n",
    "\n",
    "for s in train:\n",
    "    task_dt['train'].setdefault('text', list()).append(s)\n",
    "\n",
    "for s in dev:\n",
    "    task_dt['dev'].setdefault('text', list()).append(s)\n",
    "\n",
    "task_dt = DatasetDict({k: Dataset.from_dict(task_dt[k]) for k in task_dt.keys() if k != 'test'})\n",
    "task_dt.flatten()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "tokenizer.add_tokens(['[DATE]', '[TIME]'], special_tokens=True)\n",
    "tkn_dt = task_dt.map(tokenize_function, batched=True, num_proc=4)\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93d74891-6e78-4963-b7a1-cf5a2b10477c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6300e612ce66472d8e3b25dfb4fb2e6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/713M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 06:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Perplexity: 8.53\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    model = AutoModelForMaskedLM.from_pretrained(\n",
    "        MODEL,\n",
    "        from_tf=False).to('cuda')\n",
    "    print_gpu_utilization()\n",
    "else:\n",
    "    model = AutoModelForMaskedLM.from_pretrained(\n",
    "        MODEL,\n",
    "        from_tf=False)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "batch_size = 4 # [4, 8, 16]\n",
    "logging_steps = len(task_dt[\"train\"]) // batch_size\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"runs/ta_pretraining\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-6, # [5e-6, 1e-5]\n",
    "    num_train_epochs=5, \n",
    "    weight_decay=0.01, # [1e-6, 1e-4, 1e-8]\n",
    "    warmup_ratio=0.01, #[1e-6, 1e-4, 1e-8]\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    save_strategy='epoch',\n",
    "    save_total_limit=2,\n",
    "    logging_steps=logging_steps,\n",
    "    adam_epsilon=1e-6, # try to add AdamW optimizer post changing the batch size\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tkn_dt['train'],\n",
    "    eval_dataset=tkn_dt['dev'],\n",
    "    data_collator=data_collator   \n",
    ")\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beccc058-7398-440e-ac9e-c226f5c4743a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valena17/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='435' max='435' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [435/435 1:00:54, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.219600</td>\n",
       "      <td>1.611951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.943800</td>\n",
       "      <td>1.812136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.919200</td>\n",
       "      <td>1.327535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.938300</td>\n",
       "      <td>1.818197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.652100</td>\n",
       "      <td>1.596408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainOutput(global_step=435, training_loss=1.9247360437765888, metrics={'train_runtime': 3663.7745, 'train_samples_per_second': 0.472, 'train_steps_per_second': 0.119, 'total_flos': 186999608016000.0, 'train_loss': 1.9247360437765888, 'epoch': 5.0})\n"
     ]
    }
   ],
   "source": [
    "result = trainer.train()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88f20150-a6f8-4d10-b7c3-cfd3d39f3ec7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Perplexity: 4.89\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "acac37a2-bb1a-477c-bfda-79d8f62541d4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8e8d4a-042e-48eb-9ef3-3bd286af6033",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
