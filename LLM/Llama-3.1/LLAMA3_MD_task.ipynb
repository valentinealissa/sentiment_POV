{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4ca3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from accelerate import Accelerator\n",
    "from accelerate.utils import gather_object\n",
    "from statistics import mean\n",
    "import transformers\n",
    "import torch, time, json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:40\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "accelerator = Accelerator()\n",
    "\n",
    "# load a base model and tokenizer\n",
    "access_token = #your token here\n",
    "\n",
    "model_name = 'meta-llama/Meta-Llama-3.1-8B-Instruct'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token=access_token, cache_dir='./')\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, token=access_token, cache_dir='./',\n",
    "                                             device_map='auto',\n",
    "                                             torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b650d0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(predictions, references, labels=None, pos_label=1, average=\"weighted\", sample_weight=None, zero_division='warn'):\n",
    "        f1 = f1_score(\n",
    "            references, predictions, labels=labels, pos_label=pos_label, average=average, sample_weight=sample_weight\n",
    "        )\n",
    "        p = precision_score(\n",
    "            references, predictions, labels=labels, pos_label=pos_label, average=average, sample_weight=sample_weight,\n",
    "            zero_division=zero_division\n",
    "        )\n",
    "        r = recall_score(\n",
    "            references, predictions, labels=labels, pos_label=pos_label, average=average, sample_weight=sample_weight,\n",
    "            zero_division=zero_division\n",
    "        )\n",
    "        c = classification_report(\n",
    "            references, predictions, labels=labels\n",
    "        )\n",
    "        print(c)\n",
    "        return {\"f1\": float(f1) if f1.size == 1 else f1,\n",
    "                \"precision\": float(p) if p.size == 1 else p,\n",
    "                \"recall\": float(r) if r.size == 1 else r}\n",
    "\n",
    "def train_sentence_selection(df, n_neutral, n_positive, n_negative, label, seed):\n",
    "    # saving column name given PT or MD label\n",
    "    label = f\"{label}_label\"\n",
    "    # randomly selecting 1-2 sentences per label\n",
    "    neutral_sentences = df[df[label] == \"neutral\"].sample(n_neutral, replace=False, random_state=seed)\n",
    "    positive_sentences = df[df[label] == \"positive\"].sample(n_positive, replace=False, random_state=seed)\n",
    "    negative_sentences = df[df[label] == \"negative\"].sample(n_negative, replace=False, random_state=seed)\n",
    "    all_sentences = pd.concat([neutral_sentences,\n",
    "                               positive_sentences,\n",
    "                               negative_sentences], ignore_index = True)\n",
    "    return all_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51fac0f-1580-40e7-8008-c85d43637dc8",
   "metadata": {},
   "source": [
    "### Zero-shot approach\n",
    "Below is code to evaluate the model with a zero-shot approach.\n",
    "Update the right dataset and file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "974dd9f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accelerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## zero shot approach\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43maccelerator\u001b[49m\u001b[38;5;241m.\u001b[39mwait_for_everyone()\n\u001b[1;32m      3\u001b[0m start\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# dataset = \"no_agreement\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# test = pd.read_csv(f\"/sc/arion/projects/mscic1/psych_nlp/sentiment_analysis/data/all_no_agreement.csv\")\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accelerator' is not defined"
     ]
    }
   ],
   "source": [
    "## zero shot approach\n",
    "accelerator.wait_for_everyone()\n",
    "start=time.time()\n",
    "\n",
    "dataset = \"80\" #example, evaluating the model on sentences with at least 80% agreement\n",
    "\n",
    "test = pd.read_csv(f\"yourpath/data/test_{dataset}.csv\")\n",
    "\n",
    "# converting test sentences to json format\n",
    "json_test_sentences = test[\"language\"].to_json()\n",
    "\n",
    "# creating context prompt\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "<|start_header_id|>system<|end_header_id|>\n",
    "You are a doctor familair with medical jargon that writes many clinical notes about patients.<|eot_id|>\n",
    "\"\"\"\n",
    "\n",
    "PROMPTS = []\n",
    "\n",
    "for sentence in test[\"language\"]:\n",
    "    \n",
    "    USER_PROMPT_1 = f\"\"\"\n",
    "    <|start_header_id|>user<|end_header_id|>\n",
    "    Your task is to analyze the sentiment of a sentences you wrote about a patient.\n",
    "    For each sentence, what is your attitude towards the patient you wrote about?\n",
    "    Answer the question by assigning a sentiment score of negative, neutral, or positive for the sentence.\n",
    "    Only output your sentiment score in JSON format for this sentence:\n",
    "    {{\"0\":\\\"{sentence}\\\"}}<|eot_id|>\n",
    "    <|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\"\n",
    "    \n",
    "    PROMPT = [f\"\"\"\n",
    "    {SYSTEM_PROMPT}\n",
    "    {USER_PROMPT_1}\n",
    "    \"\"\"]\n",
    "    PROMPTS.append(PROMPT)\n",
    "\n",
    "\n",
    "with accelerator.split_between_processes(PROMPTS) as prompts:\n",
    "    # store output of generations in dict   \n",
    "    results=dict(outputs=[])\n",
    "\n",
    "    # have each GPU do inference, prompt by prompt\n",
    "    for prompt in prompts:\n",
    "        prompt_tokenized=tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        output_tokenized = model.generate(**prompt_tokenized, max_new_tokens=10, do_sample=True, temperature=0.001, pad_token_id=tokenizer.eos_token_id)[0]\n",
    "\n",
    "        # remove prompt from output\n",
    "        output_tokenized=output_tokenized[len(prompt_tokenized[\"input_ids\"][0]):]\n",
    "\n",
    "        # store outputs and number of tokens in result{}\n",
    "        results[\"outputs\"].append( tokenizer.decode(output_tokenized) )\n",
    "#         results[\"num_tokens\"].append(len(output_tokenized))\n",
    "\n",
    "        \n",
    "    results=[ results ] # transform to list, otherwise gather_object() will not collect correctly\n",
    "\n",
    "    # collect results from all the GPUs\n",
    "results_gathered=gather_object(results)\n",
    "# print(results_gathered)\n",
    "\n",
    "results = results_gathered[0]['outputs']\n",
    "parsed_results = []\n",
    "for label in results:\n",
    "    label = label.strip().replace('<|eot_id|>', '')\n",
    "    parsed_results.append(label)\n",
    "    \n",
    "parsed_data = [json.loads(item) for item in parsed_results]\n",
    "df = pd.DataFrame(parsed_data)\n",
    "df.columns = ['Model_label']\n",
    "\n",
    "results = compute_metrics(df['Model_label'], test[\"MD_label\"])\n",
    "print(results)\n",
    "\n",
    "error_analysis = pd.concat([test[[\"idx\", \"language\", \"MD_PT_label\", \"MD_label\"]], df['Model_label']], axis=1)\n",
    "error_analysis = error_analysis.rename(columns={'Model_label':\"pred\", \"MD_label\":\"true\"})\n",
    "mask = error_analysis[\"pred\"] == error_analysis[\"true\"]\n",
    "error_analysis = error_analysis[~ mask]\n",
    "error_analysis.to_csv(f'MD_error_analysis_zero_shot_validation_{dataset}.csv', index=False)\n",
    "print('-' * 100)\n",
    "print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94ead66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      1.00      0.91        10\n",
      "     neutral       0.00      0.00      0.00         3\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.80        15\n",
      "   macro avg       0.50      0.67      0.57        15\n",
      "weighted avg       0.64      0.80      0.71        15\n",
      "\n",
      "{'f1': 0.7127272727272727, 'precision': 0.6444444444444445, 'recall': 0.8}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/packages/minerva-centos7/py_packages/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/hpc/packages/minerva-centos7/py_packages/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/hpc/packages/minerva-centos7/py_packages/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/hpc/packages/minerva-centos7/py_packages/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "## best CLI performance on test sentences\n",
    "accelerator.wait_for_everyone()\n",
    "start=time.time()\n",
    "\n",
    "dataset = \"60\"\n",
    "\n",
    "train = pd.read_csv(f\"/sc/arion/projects/mscic1/psych_nlp/sentiment_analysis/MD_task/LLAMA3/best_CLI_sentences_{dataset}.csv\")\n",
    "test = pd.read_csv(f\"/sc/arion/projects/mscic1/psych_nlp/sentiment_analysis/data/validation_sentences.csv\")\n",
    "\n",
    "#context sentences in json format\n",
    "json_train_sentences = train[\"language\"].to_json()\n",
    "json_train_labels = train[\"MD_label\"].to_json()\n",
    "\n",
    "# converting test sentences to json format\n",
    "json_test_sentences = test[\"language\"].to_json()\n",
    "\n",
    "# creating context prompt\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "<|start_header_id|>system<|end_header_id|>\n",
    "You are a doctor familair with medical jargon that writes many clinical notes about patients.<|eot_id|>\n",
    "\"\"\"\n",
    "\n",
    "USER_PROMPT_1 = f\"\"\"\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Your task is to analyze the sentiment of a series of sentences you wrote about patients.\n",
    "For each sentence, what is your attitude towards the patient you wrote about?\n",
    "Answer the question by assigning a sentiment score of negative, neutral, or positive for each sentence.\n",
    "Output your anser in JSON format. Donâ€™t add explanation beyond the JSON.\n",
    "Below are some example sentences in JSON format:\n",
    "{json_train_sentences}<|eot_id|>\n",
    "\"\"\"\n",
    "\n",
    "ASSISTANT_PROMPT = f\"\"\"\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "f{json_train_labels}<|eot_id|>\n",
    "\"\"\"\n",
    "\n",
    "PROMPTS = []\n",
    "\n",
    "for sentence in test[\"language\"]:\n",
    "    \n",
    "    USER_PROMPT_2 = f\"\"\"\n",
    "    <|start_header_id|>user<|end_header_id|>\n",
    "    Complete the same task with this sentence and only return your sentiment score in JSON format:\\n\"{sentence}\"<|eot_id|>\n",
    "    <|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\"\n",
    "    \n",
    "    PROMPT = [f\"\"\"\n",
    "    {SYSTEM_PROMPT}\n",
    "    {USER_PROMPT_1}\n",
    "    {ASSISTANT_PROMPT}\n",
    "    {USER_PROMPT_2}\n",
    "    \"\"\"]\n",
    "    PROMPTS.append(PROMPT)\n",
    "\n",
    "\n",
    "with accelerator.split_between_processes(PROMPTS) as prompts:\n",
    "    # store output of generations in dict   \n",
    "    results=dict(outputs=[])\n",
    "\n",
    "    # have each GPU do inference, prompt by prompt\n",
    "    for prompt in prompts:\n",
    "        prompt_tokenized=tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        output_tokenized = model.generate(**prompt_tokenized, max_new_tokens=10, do_sample=True, temperature=0.001, pad_token_id=tokenizer.eos_token_id)[0]\n",
    "\n",
    "        # remove prompt from output\n",
    "        output_tokenized=output_tokenized[len(prompt_tokenized[\"input_ids\"][0]):]\n",
    "\n",
    "        # store outputs and number of tokens in result{}\n",
    "        results[\"outputs\"].append( tokenizer.decode(output_tokenized) )\n",
    "#         results[\"num_tokens\"].append(len(output_tokenized))\n",
    "\n",
    "        \n",
    "    results=[ results ] # transform to list, otherwise gather_object() will not collect correctly\n",
    "\n",
    "    # collect results from all the GPUs\n",
    "results_gathered=gather_object(results)\n",
    "\n",
    "# if accelerator.is_main_process:\n",
    "#     timediff=time.time()-start\n",
    "#     num_tokens=sum([r[\"num_tokens\"] for r in results_gathered ])\n",
    "\n",
    "#     print(f\"tokens/sec: {num_tokens//timediff}, time {timediff}, total tokens {num_tokens}, total prompts {len(PROMPT)}\")\n",
    "\n",
    "results = results_gathered[0]['outputs']\n",
    "parsed_results = []\n",
    "for label in results:\n",
    "    label = label.strip().replace('<|eot_id|>', '')\n",
    "    parsed_results.append(label)\n",
    "    \n",
    "parsed_data = [json.loads(item) for item in parsed_results]\n",
    "df = pd.DataFrame(parsed_data)\n",
    "df.columns = ['Model_label']\n",
    "\n",
    "results = compute_metrics(df['Model_label'], test[\"MD_label\"])\n",
    "print(results)\n",
    "\n",
    "error_analysis = pd.concat([test[[\"idx\", \"language\", \"MD_PT_label\", \"MD_label\"]], df['Model_label']], axis=1)\n",
    "# print(error_analysis)\n",
    "error_analysis = error_analysis.rename(columns={'Model_label':\"pred\", \"MD_label\":\"true\"})\n",
    "mask = error_analysis[\"pred\"] == error_analysis[\"true\"]\n",
    "error_analysis = error_analysis[~ mask]\n",
    "error_analysis.to_csv(f'error_analysis_test_{dataset}.csv', index=False)\n",
    "print('-' * 100)\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2dcd675d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'outputs': [' {\\n  \"sentiment\": \"positive\"\\n}',\n",
       "   ' {\\n  \"sentiment\": \"negative\"\\n}',\n",
       "   ' {\\n  \"sentiment\": \"negative\"\\n}',\n",
       "   ' {\\n  \"sentiment\": \"positive\"\\n}',\n",
       "   ' {\\n  \"sentiment\": \"positive\"\\n}',\n",
       "   ' {\\n  \"sentiment\": \"negative\"\\n}',\n",
       "   ' {\\n  \"sentiment\": \"negative\"\\n}',\n",
       "   ' {\\n  \"sentiment\": \"neutral\"\\n}',\n",
       "   ' {\\n  \"sentiment\": \"neutral\"\\n}',\n",
       "   ' {\\n  \"sentiment\": \"neutral\"\\n}',\n",
       "   ' {\\n  \"sentiment\": \"positive\"\\n}',\n",
       "   ' {\\n  \"sentiment\": \"negative\"\\n}',\n",
       "   ' {\\n  \"sentiment\": \"negative\"\\n}',\n",
       "   ' {\\n  \"sentiment\": \"negative\"\\n}',\n",
       "   ' {\\n  \"sentiment\": \"negative\"\\n}',\n",
       "   ' {\\n  \"sentiment\": \"neutral\"\\n}',\n",
       "   ' {\\n  \"sentiment\": \"positive\"\\n}',\n",
       "   ' {\\n  \"sentiment\": \"positive\"\\n}',\n",
       "   ' {\\n  \"sentiment\": \"negative\"\\n}',\n",
       "   ' {\\n  \"sentiment\": \"positive\"\\n}',\n",
       "   ' {\\n  \"sentiment\": \"positive\"\\n}',\n",
       "   ' {\\n  \"sentiment\": \"neutral\"\\n}',\n",
       "   ' {\\n  \"sentiment\": \"negative\"\\n}',\n",
       "   ' {\\n  \"sentiment\": \"negative\"\\n}',\n",
       "   ' {\\n  \"sentiment\": \"positive\"\\n}',\n",
       "   ' {\\n  \"sentiment\": \"negative\"\\n}',\n",
       "   ' {\\n  \"sentiment\": \"neutral\"\\n}',\n",
       "   ' {\\n  \"sentiment\": \"negative\"\\n}']}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_gathered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e38d247",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594b1529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8de4edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with: 0 negative, 0 neutral, 0 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      1.00      0.86         9\n",
      "     neutral       1.00      0.67      0.80        15\n",
      "    positive       0.67      1.00      0.80         4\n",
      "\n",
      "    accuracy                           0.82        28\n",
      "   macro avg       0.81      0.89      0.82        28\n",
      "weighted avg       0.87      0.82      0.82        28\n",
      "\n",
      "{'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 0 negative, 0 neutral, 1 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      1.00      0.82         9\n",
      "     neutral       1.00      0.53      0.70        15\n",
      "    positive       0.57      1.00      0.73         4\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.75      0.84      0.75        28\n",
      "weighted avg       0.84      0.75      0.74        28\n",
      "\n",
      "{'f1': 0.7395539243365331, 'precision': 0.8398744113029827, 'recall': 0.75}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 0 negative, 0 neutral, 2 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      1.00      0.82         9\n",
      "     neutral       1.00      0.53      0.70        15\n",
      "    positive       0.57      1.00      0.73         4\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.75      0.84      0.75        28\n",
      "weighted avg       0.84      0.75      0.74        28\n",
      "\n",
      "{'f1': 0.7395539243365331, 'precision': 0.8398744113029827, 'recall': 0.75}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 0 negative, 1 neutral, 0 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.89      0.80         9\n",
      "     neutral       0.88      0.47      0.61        15\n",
      "    positive       0.44      1.00      0.62         4\n",
      "\n",
      "    accuracy                           0.68        28\n",
      "   macro avg       0.68      0.79      0.67        28\n",
      "weighted avg       0.77      0.68      0.67        28\n",
      "\n",
      "{'f1': 0.6711419015766841, 'precision': 0.7660082972582973, 'recall': 0.6785714285714286}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 0 negative, 1 neutral, 1 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.89      0.84         9\n",
      "     neutral       0.91      0.67      0.77        15\n",
      "    positive       0.57      1.00      0.73         4\n",
      "\n",
      "    accuracy                           0.79        28\n",
      "   macro avg       0.76      0.85      0.78        28\n",
      "weighted avg       0.83      0.79      0.79        28\n",
      "\n",
      "{'f1': 0.7866607077133392, 'precision': 0.8257884972170686, 'recall': 0.7857142857142857}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 0 negative, 1 neutral, 2 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.89      0.84         9\n",
      "     neutral       0.90      0.60      0.72        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.73      0.83      0.74        28\n",
      "weighted avg       0.81      0.75      0.75        28\n",
      "\n",
      "{'f1': 0.7516290726817043, 'precision': 0.8107142857142857, 'recall': 0.75}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 0 negative, 2 neutral, 0 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      1.00      0.86         9\n",
      "     neutral       1.00      0.47      0.64        15\n",
      "    positive       0.44      1.00      0.62         4\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.73      0.82      0.70        28\n",
      "weighted avg       0.84      0.71      0.70        28\n",
      "\n",
      "{'f1': 0.7043313829028114, 'precision': 0.8402777777777778, 'recall': 0.7142857142857143}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 0 negative, 2 neutral, 1 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.89      0.84         9\n",
      "     neutral       0.90      0.60      0.72        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.73      0.83      0.74        28\n",
      "weighted avg       0.81      0.75      0.75        28\n",
      "\n",
      "{'f1': 0.7516290726817043, 'precision': 0.8107142857142857, 'recall': 0.75}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 0 negative, 2 neutral, 2 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90         9\n",
      "     neutral       1.00      0.53      0.70        15\n",
      "    positive       0.44      1.00      0.62         4\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.75      0.84      0.74        28\n",
      "weighted avg       0.86      0.75      0.75        28\n",
      "\n",
      "{'f1': 0.7498686096512184, 'precision': 0.8621933621933622, 'recall': 0.75}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 0 negative, 3 neutral, 0 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.89      0.80         9\n",
      "     neutral       0.88      0.47      0.61        15\n",
      "    positive       0.44      1.00      0.62         4\n",
      "\n",
      "    accuracy                           0.68        28\n",
      "   macro avg       0.68      0.79      0.67        28\n",
      "weighted avg       0.77      0.68      0.67        28\n",
      "\n",
      "{'f1': 0.6711419015766841, 'precision': 0.7660082972582973, 'recall': 0.6785714285714286}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 0 negative, 3 neutral, 1 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89         9\n",
      "     neutral       0.91      0.67      0.77        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.79        28\n",
      "   macro avg       0.77      0.85      0.77        28\n",
      "weighted avg       0.84      0.79      0.79        28\n",
      "\n",
      "{'f1': 0.793040293040293, 'precision': 0.8441558441558442, 'recall': 0.7857142857142857}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 0 negative, 3 neutral, 2 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89         9\n",
      "     neutral       0.90      0.60      0.72        15\n",
      "    positive       0.44      1.00      0.62         4\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.74      0.83      0.74        28\n",
      "weighted avg       0.83      0.75      0.76        28\n",
      "\n",
      "{'f1': 0.7593406593406593, 'precision': 0.8313492063492064, 'recall': 0.75}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 0 negative, 4 neutral, 0 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      1.00      0.86         9\n",
      "     neutral       1.00      0.47      0.64        15\n",
      "    positive       0.44      1.00      0.62         4\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.73      0.82      0.70        28\n",
      "weighted avg       0.84      0.71      0.70        28\n",
      "\n",
      "{'f1': 0.7043313829028114, 'precision': 0.8402777777777778, 'recall': 0.7142857142857143}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 0 negative, 4 neutral, 1 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.89      0.80         9\n",
      "     neutral       0.89      0.53      0.67        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.71      0.81      0.71        28\n",
      "weighted avg       0.78      0.71      0.71        28\n",
      "\n",
      "{'f1': 0.7095238095238097, 'precision': 0.7813852813852814, 'recall': 0.7142857142857143}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 0 negative, 4 neutral, 2 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.89      0.84         9\n",
      "     neutral       0.90      0.60      0.72        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.73      0.83      0.74        28\n",
      "weighted avg       0.81      0.75      0.75        28\n",
      "\n",
      "{'f1': 0.7516290726817043, 'precision': 0.8107142857142857, 'recall': 0.75}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 0 negative, 5 neutral, 0 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.89      0.80         9\n",
      "     neutral       0.88      0.47      0.61        15\n",
      "    positive       0.44      1.00      0.62         4\n",
      "\n",
      "    accuracy                           0.68        28\n",
      "   macro avg       0.68      0.79      0.67        28\n",
      "weighted avg       0.77      0.68      0.67        28\n",
      "\n",
      "{'f1': 0.6711419015766841, 'precision': 0.7660082972582973, 'recall': 0.6785714285714286}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 0 negative, 5 neutral, 1 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.89      0.84         9\n",
      "     neutral       0.91      0.67      0.77        15\n",
      "    positive       0.57      1.00      0.73         4\n",
      "\n",
      "    accuracy                           0.79        28\n",
      "   macro avg       0.76      0.85      0.78        28\n",
      "weighted avg       0.83      0.79      0.79        28\n",
      "\n",
      "{'f1': 0.7866607077133392, 'precision': 0.8257884972170686, 'recall': 0.7857142857142857}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 0 negative, 5 neutral, 2 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.89      0.84         9\n",
      "     neutral       0.91      0.67      0.77        15\n",
      "    positive       0.57      1.00      0.73         4\n",
      "\n",
      "    accuracy                           0.79        28\n",
      "   macro avg       0.76      0.85      0.78        28\n",
      "weighted avg       0.83      0.79      0.79        28\n",
      "\n",
      "{'f1': 0.7866607077133392, 'precision': 0.8257884972170686, 'recall': 0.7857142857142857}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 0 negative, 6 neutral, 0 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.89      0.80         9\n",
      "     neutral       0.90      0.60      0.72        15\n",
      "    positive       0.57      1.00      0.73         4\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.73      0.83      0.75        28\n",
      "weighted avg       0.80      0.75      0.75        28\n",
      "\n",
      "{'f1': 0.7467532467532468, 'precision': 0.7975417439703154, 'recall': 0.75}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 0 negative, 6 neutral, 1 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.89      0.80         9\n",
      "     neutral       0.90      0.60      0.72        15\n",
      "    positive       0.57      1.00      0.73         4\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.73      0.83      0.75        28\n",
      "weighted avg       0.80      0.75      0.75        28\n",
      "\n",
      "{'f1': 0.7467532467532468, 'precision': 0.7975417439703154, 'recall': 0.75}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 0 negative, 6 neutral, 2 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.89      0.84         9\n",
      "     neutral       0.91      0.67      0.77        15\n",
      "    positive       0.57      1.00      0.73         4\n",
      "\n",
      "    accuracy                           0.79        28\n",
      "   macro avg       0.76      0.85      0.78        28\n",
      "weighted avg       0.83      0.79      0.79        28\n",
      "\n",
      "{'f1': 0.7866607077133392, 'precision': 0.8257884972170686, 'recall': 0.7857142857142857}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 1 negative, 0 neutral, 0 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      1.00      0.82         9\n",
      "     neutral       1.00      0.47      0.64        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.73      0.82      0.71        28\n",
      "weighted avg       0.83      0.71      0.70        28\n",
      "\n",
      "{'f1': 0.699134199134199, 'precision': 0.8296703296703296, 'recall': 0.7142857142857143}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 1 negative, 0 neutral, 1 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.89      0.80         9\n",
      "     neutral       0.89      0.53      0.67        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.71      0.81      0.71        28\n",
      "weighted avg       0.78      0.71      0.71        28\n",
      "\n",
      "{'f1': 0.7095238095238097, 'precision': 0.7813852813852814, 'recall': 0.7142857142857143}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 1 negative, 0 neutral, 2 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      1.00      0.86         9\n",
      "     neutral       1.00      0.53      0.70        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.75      0.84      0.74        28\n",
      "weighted avg       0.85      0.75      0.74        28\n",
      "\n",
      "{'f1': 0.7434191067731442, 'precision': 0.8482142857142857, 'recall': 0.75}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 1 negative, 1 neutral, 0 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.89      0.84         9\n",
      "     neutral       0.90      0.60      0.72        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.73      0.83      0.74        28\n",
      "weighted avg       0.81      0.75      0.75        28\n",
      "\n",
      "{'f1': 0.7516290726817043, 'precision': 0.8107142857142857, 'recall': 0.75}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 1 negative, 1 neutral, 1 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.89      0.80         9\n",
      "     neutral       0.89      0.53      0.67        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.71      0.81      0.71        28\n",
      "weighted avg       0.78      0.71      0.71        28\n",
      "\n",
      "{'f1': 0.7095238095238097, 'precision': 0.7813852813852814, 'recall': 0.7142857142857143}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 1 negative, 1 neutral, 2 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.89      0.80         9\n",
      "     neutral       0.89      0.53      0.67        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.71      0.81      0.71        28\n",
      "weighted avg       0.78      0.71      0.71        28\n",
      "\n",
      "{'f1': 0.7095238095238097, 'precision': 0.7813852813852814, 'recall': 0.7142857142857143}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 1 negative, 2 neutral, 0 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.89      0.76         9\n",
      "     neutral       0.88      0.47      0.61        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.68        28\n",
      "   macro avg       0.68      0.79      0.68        28\n",
      "weighted avg       0.75      0.68      0.67        28\n",
      "\n",
      "{'f1': 0.6662230109435079, 'precision': 0.7544642857142857, 'recall': 0.6785714285714286}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 1 negative, 2 neutral, 1 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.89      0.80         9\n",
      "     neutral       0.89      0.53      0.67        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.71      0.81      0.71        28\n",
      "weighted avg       0.78      0.71      0.71        28\n",
      "\n",
      "{'f1': 0.7095238095238097, 'precision': 0.7813852813852814, 'recall': 0.7142857142857143}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 1 negative, 2 neutral, 2 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.89      0.80         9\n",
      "     neutral       0.89      0.53      0.67        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.71      0.81      0.71        28\n",
      "weighted avg       0.78      0.71      0.71        28\n",
      "\n",
      "{'f1': 0.7095238095238097, 'precision': 0.7813852813852814, 'recall': 0.7142857142857143}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 1 negative, 3 neutral, 0 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.89      0.76         9\n",
      "     neutral       0.88      0.47      0.61        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.68        28\n",
      "   macro avg       0.68      0.79      0.68        28\n",
      "weighted avg       0.75      0.68      0.67        28\n",
      "\n",
      "{'f1': 0.6662230109435079, 'precision': 0.7544642857142857, 'recall': 0.6785714285714286}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 1 negative, 3 neutral, 1 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.89      0.80         9\n",
      "     neutral       0.89      0.53      0.67        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.71      0.81      0.71        28\n",
      "weighted avg       0.78      0.71      0.71        28\n",
      "\n",
      "{'f1': 0.7095238095238097, 'precision': 0.7813852813852814, 'recall': 0.7142857142857143}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 1 negative, 3 neutral, 2 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.89      0.84         9\n",
      "     neutral       0.90      0.60      0.72        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.73      0.83      0.74        28\n",
      "weighted avg       0.81      0.75      0.75        28\n",
      "\n",
      "{'f1': 0.7516290726817043, 'precision': 0.8107142857142857, 'recall': 0.75}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 1 negative, 4 neutral, 0 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.89      0.80         9\n",
      "     neutral       0.89      0.53      0.67        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.71      0.81      0.71        28\n",
      "weighted avg       0.78      0.71      0.71        28\n",
      "\n",
      "{'f1': 0.7095238095238097, 'precision': 0.7813852813852814, 'recall': 0.7142857142857143}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 1 negative, 4 neutral, 1 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.89      0.80         9\n",
      "     neutral       0.89      0.53      0.67        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.71      0.81      0.71        28\n",
      "weighted avg       0.78      0.71      0.71        28\n",
      "\n",
      "{'f1': 0.7095238095238097, 'precision': 0.7813852813852814, 'recall': 0.7142857142857143}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 1 negative, 4 neutral, 2 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.89      0.80         9\n",
      "     neutral       0.89      0.53      0.67        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.71      0.81      0.71        28\n",
      "weighted avg       0.78      0.71      0.71        28\n",
      "\n",
      "{'f1': 0.7095238095238097, 'precision': 0.7813852813852814, 'recall': 0.7142857142857143}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 1 negative, 5 neutral, 0 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.89      0.76         9\n",
      "     neutral       0.89      0.53      0.67        15\n",
      "    positive       0.57      1.00      0.73         4\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.71      0.81      0.72        28\n",
      "weighted avg       0.77      0.71      0.71        28\n",
      "\n",
      "{'f1': 0.7059369202226347, 'precision': 0.7721088435374149, 'recall': 0.7142857142857143}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 1 negative, 5 neutral, 1 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.89      0.80         9\n",
      "     neutral       0.90      0.60      0.72        15\n",
      "    positive       0.57      1.00      0.73         4\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.73      0.83      0.75        28\n",
      "weighted avg       0.80      0.75      0.75        28\n",
      "\n",
      "{'f1': 0.7467532467532468, 'precision': 0.7975417439703154, 'recall': 0.75}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 1 negative, 5 neutral, 2 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.89      0.84         9\n",
      "     neutral       0.90      0.60      0.72        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.73      0.83      0.74        28\n",
      "weighted avg       0.81      0.75      0.75        28\n",
      "\n",
      "{'f1': 0.7516290726817043, 'precision': 0.8107142857142857, 'recall': 0.75}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 1 negative, 6 neutral, 0 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.89      0.76         9\n",
      "     neutral       0.88      0.47      0.61        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.68        28\n",
      "   macro avg       0.68      0.79      0.68        28\n",
      "weighted avg       0.75      0.68      0.67        28\n",
      "\n",
      "{'f1': 0.6662230109435079, 'precision': 0.7544642857142857, 'recall': 0.6785714285714286}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 1 negative, 6 neutral, 1 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      1.00      0.86         9\n",
      "     neutral       1.00      0.60      0.75        15\n",
      "    positive       0.57      1.00      0.73         4\n",
      "\n",
      "    accuracy                           0.79        28\n",
      "   macro avg       0.77      0.87      0.78        28\n",
      "weighted avg       0.86      0.79      0.78        28\n",
      "\n",
      "{'f1': 0.7811920222634507, 'precision': 0.8584183673469388, 'recall': 0.7857142857142857}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 1 negative, 6 neutral, 2 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      1.00      0.90         9\n",
      "     neutral       1.00      0.60      0.75        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.79        28\n",
      "   macro avg       0.77      0.87      0.77        28\n",
      "weighted avg       0.87      0.79      0.79        28\n",
      "\n",
      "{'f1': 0.7863095238095238, 'precision': 0.8701298701298701, 'recall': 0.7857142857142857}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 2 negative, 0 neutral, 0 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      1.00      0.86         9\n",
      "     neutral       1.00      0.53      0.70        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.75      0.84      0.74        28\n",
      "weighted avg       0.85      0.75      0.74        28\n",
      "\n",
      "{'f1': 0.7434191067731442, 'precision': 0.8482142857142857, 'recall': 0.75}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 2 negative, 0 neutral, 1 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      1.00      0.86         9\n",
      "     neutral       1.00      0.47      0.64        15\n",
      "    positive       0.44      1.00      0.62         4\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.73      0.82      0.70        28\n",
      "weighted avg       0.84      0.71      0.70        28\n",
      "\n",
      "{'f1': 0.7043313829028114, 'precision': 0.8402777777777778, 'recall': 0.7142857142857143}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 2 negative, 0 neutral, 2 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      1.00      0.86         9\n",
      "     neutral       1.00      0.53      0.70        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.75      0.84      0.74        28\n",
      "weighted avg       0.85      0.75      0.74        28\n",
      "\n",
      "{'f1': 0.7434191067731442, 'precision': 0.8482142857142857, 'recall': 0.75}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 2 negative, 1 neutral, 0 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.89      0.80         9\n",
      "     neutral       0.89      0.53      0.67        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.71      0.81      0.71        28\n",
      "weighted avg       0.78      0.71      0.71        28\n",
      "\n",
      "{'f1': 0.7095238095238097, 'precision': 0.7813852813852814, 'recall': 0.7142857142857143}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 2 negative, 1 neutral, 1 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.89      0.80         9\n",
      "     neutral       0.89      0.53      0.67        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.71      0.81      0.71        28\n",
      "weighted avg       0.78      0.71      0.71        28\n",
      "\n",
      "{'f1': 0.7095238095238097, 'precision': 0.7813852813852814, 'recall': 0.7142857142857143}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 2 negative, 1 neutral, 2 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      1.00      0.86         9\n",
      "     neutral       1.00      0.53      0.70        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.75      0.84      0.74        28\n",
      "weighted avg       0.85      0.75      0.74        28\n",
      "\n",
      "{'f1': 0.7434191067731442, 'precision': 0.8482142857142857, 'recall': 0.75}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 2 negative, 2 neutral, 0 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.89      0.76         9\n",
      "     neutral       0.88      0.47      0.61        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.68        28\n",
      "   macro avg       0.68      0.79      0.68        28\n",
      "weighted avg       0.75      0.68      0.67        28\n",
      "\n",
      "{'f1': 0.6662230109435079, 'precision': 0.7544642857142857, 'recall': 0.6785714285714286}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 2 negative, 2 neutral, 1 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.89      0.80         9\n",
      "     neutral       0.89      0.53      0.67        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.71      0.81      0.71        28\n",
      "weighted avg       0.78      0.71      0.71        28\n",
      "\n",
      "{'f1': 0.7095238095238097, 'precision': 0.7813852813852814, 'recall': 0.7142857142857143}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 2 negative, 2 neutral, 2 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.89      0.80         9\n",
      "     neutral       0.89      0.53      0.67        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.71      0.81      0.71        28\n",
      "weighted avg       0.78      0.71      0.71        28\n",
      "\n",
      "{'f1': 0.7095238095238097, 'precision': 0.7813852813852814, 'recall': 0.7142857142857143}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 2 negative, 3 neutral, 0 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.89      0.76         9\n",
      "     neutral       0.88      0.47      0.61        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.68        28\n",
      "   macro avg       0.68      0.79      0.68        28\n",
      "weighted avg       0.75      0.68      0.67        28\n",
      "\n",
      "{'f1': 0.6662230109435079, 'precision': 0.7544642857142857, 'recall': 0.6785714285714286}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 2 negative, 3 neutral, 1 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.89      0.80         9\n",
      "     neutral       0.89      0.53      0.67        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.71      0.81      0.71        28\n",
      "weighted avg       0.78      0.71      0.71        28\n",
      "\n",
      "{'f1': 0.7095238095238097, 'precision': 0.7813852813852814, 'recall': 0.7142857142857143}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 2 negative, 3 neutral, 2 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.89      0.80         9\n",
      "     neutral       0.89      0.53      0.67        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.71      0.81      0.71        28\n",
      "weighted avg       0.78      0.71      0.71        28\n",
      "\n",
      "{'f1': 0.7095238095238097, 'precision': 0.7813852813852814, 'recall': 0.7142857142857143}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 2 negative, 4 neutral, 0 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.89      0.80         9\n",
      "     neutral       0.89      0.53      0.67        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.71      0.81      0.71        28\n",
      "weighted avg       0.78      0.71      0.71        28\n",
      "\n",
      "{'f1': 0.7095238095238097, 'precision': 0.7813852813852814, 'recall': 0.7142857142857143}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 2 negative, 4 neutral, 1 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.89      0.80         9\n",
      "     neutral       0.90      0.60      0.72        15\n",
      "    positive       0.57      1.00      0.73         4\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.73      0.83      0.75        28\n",
      "weighted avg       0.80      0.75      0.75        28\n",
      "\n",
      "{'f1': 0.7467532467532468, 'precision': 0.7975417439703154, 'recall': 0.75}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 2 negative, 4 neutral, 2 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.89      0.80         9\n",
      "     neutral       0.89      0.53      0.67        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.71      0.81      0.71        28\n",
      "weighted avg       0.78      0.71      0.71        28\n",
      "\n",
      "{'f1': 0.7095238095238097, 'precision': 0.7813852813852814, 'recall': 0.7142857142857143}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 2 negative, 5 neutral, 0 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.89      0.76         9\n",
      "     neutral       0.88      0.47      0.61        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.68        28\n",
      "   macro avg       0.68      0.79      0.68        28\n",
      "weighted avg       0.75      0.68      0.67        28\n",
      "\n",
      "{'f1': 0.6662230109435079, 'precision': 0.7544642857142857, 'recall': 0.6785714285714286}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 2 negative, 5 neutral, 1 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.89      0.80         9\n",
      "     neutral       0.90      0.60      0.72        15\n",
      "    positive       0.57      1.00      0.73         4\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.73      0.83      0.75        28\n",
      "weighted avg       0.80      0.75      0.75        28\n",
      "\n",
      "{'f1': 0.7467532467532468, 'precision': 0.7975417439703154, 'recall': 0.75}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 2 negative, 5 neutral, 2 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      1.00      0.86         9\n",
      "     neutral       1.00      0.60      0.75        15\n",
      "    positive       0.57      1.00      0.73         4\n",
      "\n",
      "    accuracy                           0.79        28\n",
      "   macro avg       0.77      0.87      0.78        28\n",
      "weighted avg       0.86      0.79      0.78        28\n",
      "\n",
      "{'f1': 0.7811920222634507, 'precision': 0.8584183673469388, 'recall': 0.7857142857142857}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 2 negative, 6 neutral, 0 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      1.00      0.82         9\n",
      "     neutral       1.00      0.47      0.64        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.73      0.82      0.71        28\n",
      "weighted avg       0.83      0.71      0.70        28\n",
      "\n",
      "{'f1': 0.699134199134199, 'precision': 0.8296703296703296, 'recall': 0.7142857142857143}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 2 negative, 6 neutral, 1 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      1.00      0.86         9\n",
      "     neutral       1.00      0.53      0.70        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.75      0.84      0.74        28\n",
      "weighted avg       0.85      0.75      0.74        28\n",
      "\n",
      "{'f1': 0.7434191067731442, 'precision': 0.8482142857142857, 'recall': 0.75}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 2 negative, 6 neutral, 2 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      1.00      0.86         9\n",
      "     neutral       1.00      0.60      0.75        15\n",
      "    positive       0.57      1.00      0.73         4\n",
      "\n",
      "    accuracy                           0.79        28\n",
      "   macro avg       0.77      0.87      0.78        28\n",
      "weighted avg       0.86      0.79      0.78        28\n",
      "\n",
      "{'f1': 0.7811920222634507, 'precision': 0.8584183673469388, 'recall': 0.7857142857142857}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 3 negative, 0 neutral, 0 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      1.00      0.86         9\n",
      "     neutral       1.00      0.53      0.70        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.75      0.84      0.74        28\n",
      "weighted avg       0.85      0.75      0.74        28\n",
      "\n",
      "{'f1': 0.7434191067731442, 'precision': 0.8482142857142857, 'recall': 0.75}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 3 negative, 0 neutral, 1 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      1.00      0.86         9\n",
      "     neutral       1.00      0.40      0.57        15\n",
      "    positive       0.40      1.00      0.57         4\n",
      "\n",
      "    accuracy                           0.68        28\n",
      "   macro avg       0.72      0.80      0.67        28\n",
      "weighted avg       0.83      0.68      0.66        28\n",
      "\n",
      "{'f1': 0.6632653061224489, 'precision': 0.8339285714285715, 'recall': 0.6785714285714286}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 3 negative, 0 neutral, 2 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      1.00      0.86         9\n",
      "     neutral       1.00      0.53      0.70        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.75      0.84      0.74        28\n",
      "weighted avg       0.85      0.75      0.74        28\n",
      "\n",
      "{'f1': 0.7434191067731442, 'precision': 0.8482142857142857, 'recall': 0.75}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 3 negative, 1 neutral, 0 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      1.00      0.86         9\n",
      "     neutral       1.00      0.47      0.64        15\n",
      "    positive       0.44      1.00      0.62         4\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.73      0.82      0.70        28\n",
      "weighted avg       0.84      0.71      0.70        28\n",
      "\n",
      "{'f1': 0.7043313829028114, 'precision': 0.8402777777777778, 'recall': 0.7142857142857143}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 3 negative, 1 neutral, 1 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.89      0.80         9\n",
      "     neutral       0.89      0.53      0.67        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.71      0.81      0.71        28\n",
      "weighted avg       0.78      0.71      0.71        28\n",
      "\n",
      "{'f1': 0.7095238095238097, 'precision': 0.7813852813852814, 'recall': 0.7142857142857143}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 3 negative, 1 neutral, 2 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.89      0.80         9\n",
      "     neutral       0.89      0.53      0.67        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.71      0.81      0.71        28\n",
      "weighted avg       0.78      0.71      0.71        28\n",
      "\n",
      "{'f1': 0.7095238095238097, 'precision': 0.7813852813852814, 'recall': 0.7142857142857143}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 3 negative, 2 neutral, 0 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      1.00      0.86         9\n",
      "     neutral       1.00      0.53      0.70        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.75      0.84      0.74        28\n",
      "weighted avg       0.85      0.75      0.74        28\n",
      "\n",
      "{'f1': 0.7434191067731442, 'precision': 0.8482142857142857, 'recall': 0.75}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 3 negative, 2 neutral, 1 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.89      0.80         9\n",
      "     neutral       0.89      0.53      0.67        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.71      0.81      0.71        28\n",
      "weighted avg       0.78      0.71      0.71        28\n",
      "\n",
      "{'f1': 0.7095238095238097, 'precision': 0.7813852813852814, 'recall': 0.7142857142857143}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 3 negative, 2 neutral, 2 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      1.00      0.86         9\n",
      "     neutral       1.00      0.53      0.70        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.75      0.84      0.74        28\n",
      "weighted avg       0.85      0.75      0.74        28\n",
      "\n",
      "{'f1': 0.7434191067731442, 'precision': 0.8482142857142857, 'recall': 0.75}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 3 negative, 3 neutral, 0 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.89      0.80         9\n",
      "     neutral       0.89      0.53      0.67        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.71      0.81      0.71        28\n",
      "weighted avg       0.78      0.71      0.71        28\n",
      "\n",
      "{'f1': 0.7095238095238097, 'precision': 0.7813852813852814, 'recall': 0.7142857142857143}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 3 negative, 3 neutral, 1 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.89      0.76         9\n",
      "     neutral       0.88      0.47      0.61        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.68        28\n",
      "   macro avg       0.68      0.79      0.68        28\n",
      "weighted avg       0.75      0.68      0.67        28\n",
      "\n",
      "{'f1': 0.6662230109435079, 'precision': 0.7544642857142857, 'recall': 0.6785714285714286}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 3 negative, 3 neutral, 2 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.89      0.80         9\n",
      "     neutral       0.89      0.53      0.67        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.71      0.81      0.71        28\n",
      "weighted avg       0.78      0.71      0.71        28\n",
      "\n",
      "{'f1': 0.7095238095238097, 'precision': 0.7813852813852814, 'recall': 0.7142857142857143}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 3 negative, 4 neutral, 0 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.89      0.80         9\n",
      "     neutral       0.89      0.53      0.67        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.71      0.81      0.71        28\n",
      "weighted avg       0.78      0.71      0.71        28\n",
      "\n",
      "{'f1': 0.7095238095238097, 'precision': 0.7813852813852814, 'recall': 0.7142857142857143}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 3 negative, 4 neutral, 1 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.89      0.80         9\n",
      "     neutral       0.89      0.53      0.67        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.71      0.81      0.71        28\n",
      "weighted avg       0.78      0.71      0.71        28\n",
      "\n",
      "{'f1': 0.7095238095238097, 'precision': 0.7813852813852814, 'recall': 0.7142857142857143}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 3 negative, 4 neutral, 2 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      1.00      0.86         9\n",
      "     neutral       1.00      0.53      0.70        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.75      0.84      0.74        28\n",
      "weighted avg       0.85      0.75      0.74        28\n",
      "\n",
      "{'f1': 0.7434191067731442, 'precision': 0.8482142857142857, 'recall': 0.75}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 3 negative, 5 neutral, 0 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.89      0.76         9\n",
      "     neutral       0.88      0.47      0.61        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.68        28\n",
      "   macro avg       0.68      0.79      0.68        28\n",
      "weighted avg       0.75      0.68      0.67        28\n",
      "\n",
      "{'f1': 0.6662230109435079, 'precision': 0.7544642857142857, 'recall': 0.6785714285714286}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 3 negative, 5 neutral, 1 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      1.00      0.86         9\n",
      "     neutral       1.00      0.60      0.75        15\n",
      "    positive       0.57      1.00      0.73         4\n",
      "\n",
      "    accuracy                           0.79        28\n",
      "   macro avg       0.77      0.87      0.78        28\n",
      "weighted avg       0.86      0.79      0.78        28\n",
      "\n",
      "{'f1': 0.7811920222634507, 'precision': 0.8584183673469388, 'recall': 0.7857142857142857}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 3 negative, 5 neutral, 2 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      1.00      0.86         9\n",
      "     neutral       1.00      0.53      0.70        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.75      0.84      0.74        28\n",
      "weighted avg       0.85      0.75      0.74        28\n",
      "\n",
      "{'f1': 0.7434191067731442, 'precision': 0.8482142857142857, 'recall': 0.75}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 3 negative, 6 neutral, 0 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.89      0.76         9\n",
      "     neutral       0.88      0.47      0.61        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.68        28\n",
      "   macro avg       0.68      0.79      0.68        28\n",
      "weighted avg       0.75      0.68      0.67        28\n",
      "\n",
      "{'f1': 0.6662230109435079, 'precision': 0.7544642857142857, 'recall': 0.6785714285714286}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 3 negative, 6 neutral, 1 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.89      0.80         9\n",
      "     neutral       0.90      0.60      0.72        15\n",
      "    positive       0.57      1.00      0.73         4\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.73      0.83      0.75        28\n",
      "weighted avg       0.80      0.75      0.75        28\n",
      "\n",
      "{'f1': 0.7467532467532468, 'precision': 0.7975417439703154, 'recall': 0.75}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n",
      "Testing with: 3 negative, 6 neutral, 2 positive.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      1.00      0.86         9\n",
      "     neutral       1.00      0.53      0.70        15\n",
      "    positive       0.50      1.00      0.67         4\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.75      0.84      0.74        28\n",
      "weighted avg       0.85      0.75      0.74        28\n",
      "\n",
      "{'f1': 0.7434191067731442, 'precision': 0.8482142857142857, 'recall': 0.75}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Best combination of context sentences: {'n_negative_sentences': 0, 'n_neutral_sentences': 0, 'n_positive_sentences': 0, 'seed': 42}\n",
      "\n",
      "\n",
      "Best results: {'f1': 0.8183673469387756, 'precision': 0.8720238095238095, 'recall': 0.8214285714285714}\n"
     ]
    }
   ],
   "source": [
    "# CLI experiment\n",
    "\n",
    "accelerator.wait_for_everyone()\n",
    "start=time.time()\n",
    "# model.generation_config.temperature=None\n",
    "\n",
    "params = {\n",
    "    'seed': [42],\n",
    "    'n_neutral_sentences': [0, 1, 2, 3, 4, 5, 6],\n",
    "    'n_positive_sentences': [0, 1, 2],\n",
    "    'n_negative_sentences': [0, 1, 2, 3]\n",
    "}\n",
    "\n",
    "dataset = \"60\"\n",
    "metrics_file = f'MD_context_metrics_{dataset}.csv'\n",
    "if os.path.isfile(metrics_file):\n",
    "    f = open(metrics_file, 'a')\n",
    "else:\n",
    "    f = open(metrics_file, 'w')\n",
    "    f.write('seed,n_neutral_sentences,n_positive_sentences,n_negative_sentences,f1,precision,recall\\n')\n",
    "\n",
    "best_model = []\n",
    "best_f1 = 0.0\n",
    "best_comb, best_results = None, None\n",
    "for comb in list(ParameterGrid(params)):\n",
    "    print(f\"Testing with: {comb['n_negative_sentences']} negative, {comb['n_neutral_sentences']} neutral, {comb['n_positive_sentences']} positive.\")\n",
    "    train = pd.read_csv(f\"/sc/arion/projects/mscic1/psych_nlp/sentiment_analysis/data/train_{dataset}.csv\")\n",
    "    test = pd.read_csv(f\"/sc/arion/projects/mscic1/psych_nlp/sentiment_analysis/data/test_{dataset}.csv\")\n",
    "    # randomly selecting context sentences in json format\n",
    "    train_sentences = train_sentence_selection(train,\n",
    "                                               comb['n_neutral_sentences'],\n",
    "                                               comb['n_positive_sentences'],\n",
    "                                               comb['n_negative_sentences'],\n",
    "                                               \"MD\",\n",
    "                                               comb['seed'])\n",
    "    json_train_sentences = train_sentences[\"language\"].to_json()\n",
    "    json_train_labels = train_sentences[\"MD_label\"].to_json()\n",
    "\n",
    "    # converting test sentences to json format\n",
    "    json_test_sentences = test[\"language\"].to_json()\n",
    "    sentence_count = test['language'].size\n",
    "\n",
    "    SYSTEM_PROMPT = \"\"\"\n",
    "    <|start_header_id|>system<|end_header_id|>\n",
    "    You are a doctor familair with medical jargon that writes many clinical notes about patients.<|eot_id|>\n",
    "    \"\"\"\n",
    "\n",
    "    USER_PROMPT_1 = f\"\"\"\n",
    "    <|start_header_id|>user<|end_header_id|>\n",
    "    Your task is to analyze the sentiment of a sentence you wrote about a patient.\n",
    "    For each sentence, what is your attitude towards the patient you wrote about?\n",
    "    Answer the question by assigning a sentiment score of negative, neutral, or positive for the sentence.\n",
    "    Output your anser in JSON format. Donâ€™t add explanation beyond the JSON.\n",
    "    Below are some example sentences in JSON format:\n",
    "    {json_train_sentences}<|eot_id|>\n",
    "    \"\"\"\n",
    "\n",
    "    ASSISTANT_PROMPT = f\"\"\"\n",
    "    <|start_header_id|>assistant<|end_header_id|>\n",
    "    f{json_train_labels}<|eot_id|>\n",
    "    \"\"\"\n",
    "\n",
    "    PROMPTS = []\n",
    "\n",
    "    for sentence in test[\"language\"]:\n",
    "\n",
    "        USER_PROMPT_2 = f\"\"\"\n",
    "        <|start_header_id|>user<|end_header_id|>\n",
    "        Complete the same task with this sentence and only return your sentiment score in JSON format:\\n\"{sentence}\"<|eot_id|>\n",
    "        <|start_header_id|>assistant<|end_header_id|>\n",
    "        \"\"\"\n",
    "\n",
    "        PROMPT = [f\"\"\"\n",
    "        {SYSTEM_PROMPT}\n",
    "        {USER_PROMPT_1}\n",
    "        {ASSISTANT_PROMPT}\n",
    "        {USER_PROMPT_2}\n",
    "        \"\"\"]\n",
    "        PROMPTS.append(PROMPT)\n",
    "\n",
    "\n",
    "    with accelerator.split_between_processes(PROMPTS) as prompts:\n",
    "        # store output of generations in dict   \n",
    "        results=dict(outputs=[])\n",
    "\n",
    "        # have each GPU do inference, prompt by prompt\n",
    "        for prompt in prompts:\n",
    "            prompt_tokenized=tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "            output_tokenized = model.generate(**prompt_tokenized, max_new_tokens=10, do_sample=True, temperature=0.001, pad_token_id=tokenizer.eos_token_id)[0]\n",
    "\n",
    "            # remove prompt from output\n",
    "            output_tokenized=output_tokenized[len(prompt_tokenized[\"input_ids\"][0]):]\n",
    "\n",
    "            # store outputs and number of tokens in result{}\n",
    "            results[\"outputs\"].append( tokenizer.decode(output_tokenized) )\n",
    "    #         results[\"num_tokens\"].append(len(output_tokenized))\n",
    "\n",
    "\n",
    "        results=[ results ] # transform to list, otherwise gather_object() will not collect correctly\n",
    "\n",
    "    # collect results from all the GPUs\n",
    "    results_gathered=gather_object(results)\n",
    "\n",
    "    # if accelerator.is_main_process:\n",
    "    #     timediff=time.time()-start\n",
    "    #     num_tokens=sum([r[\"num_tokens\"] for r in results_gathered ])\n",
    "\n",
    "    #     print(f\"tokens/sec: {num_tokens//timediff}, time {timediff}, total tokens {num_tokens}, total prompts {len(PROMPT)}\")\n",
    "\n",
    "    results = results_gathered[0]['outputs']\n",
    "    parsed_results = []\n",
    "    for label in results:\n",
    "        label = label.strip().replace('<|eot_id|>', '')\n",
    "        parsed_results.append(label)\n",
    "\n",
    "    parsed_data = [json.loads(item) for item in parsed_results]\n",
    "    df = pd.DataFrame(parsed_data)\n",
    "    df.columns = ['Model_label']\n",
    "\n",
    "    results = compute_metrics(df['Model_label'], test[\"MD_label\"])\n",
    "    print(results)\n",
    "\n",
    "    \n",
    "    # saving results to metrics sheet\n",
    "    v = [comb['seed'], comb['n_neutral_sentences'], comb['n_positive_sentences'], comb['n_negative_sentences'],\n",
    "         results['f1'], results['precision'], results['recall']]\n",
    "    f.write(','.join([str(el) for el in v]) + '\\n')\n",
    "\n",
    "    if results['f1'] > best_f1:\n",
    "        best_f1 = results['f1']\n",
    "        best_comb = comb\n",
    "        best_results = results\n",
    "        best_CLI_sentences = train_sentences\n",
    "        best_CLI_sentences.to_csv(f'best_CLI_sentences_{dataset}.csv', index=False)\n",
    "        error_analysis = pd.concat([test[[\"idx\", \"language\", \"MD_PT_label\", \"MD_label\"]], df['Model_label']], axis=1)\n",
    "    #   print(error_analysis)\n",
    "        error_analysis = error_analysis.rename(columns={'Model_label':\"pred\", \"MD_label\":\"true\"})\n",
    "        mask = error_analysis[\"pred\"] == error_analysis[\"true\"]\n",
    "        error_analysis = error_analysis[~ mask]\n",
    "        error_analysis.to_csv(f'error_analysis_validation_ICL_{dataset}.csv', index=False)\n",
    "    print('-' * 100)\n",
    "    print('\\n\\n')\n",
    "    print('-' * 100)\n",
    "    print('\\n\\n')\n",
    "\n",
    "    if best_comb is not None:\n",
    "        print(f'Best combination of context sentences: {best_comb}')\n",
    "        print('\\n')\n",
    "        print(f'Best results: {best_results}')\n",
    "    torch.cuda.empty_cache()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3904fcfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
